## 香港科技大学 COMP4321 课设（2025春，Group 16）：简单搜索引擎

```
       　  　▃▆█▇▄▖
　 　 　 ▟◤▖　　　◥█▎
   　 ◢◤　 ▐　　　 　▐▉
　 ▗◤　　　▂　▗▖　　▕█▎
　◤　▗▅▖◥▄　▀◣　　█▊
▐　▕▎◥▖◣◤　　　　◢██
█◣　◥▅█▀　　　　▐██◤
▐█▙▂　　     　◢██◤
◥██◣　　　　◢▄◤
 　　▀██▅▇▀
```

[English](README_en.md)

**由于学校是以英文授课的，所以原文档为英文。本文档由 DeepSeek 翻译自英文文档，可能不准**

课设说明与目标详见 [Project_Description_25S.pdf](Project_Description_25S.pdf)。

### **1. 系统整体设计**

本搜索引擎采用模块化设计，包含 4 个“高效”协同的核心组件：

#### **1.1 网络爬虫（`spider.py`）**

- **广度优先搜索（BFS）遍历**：从用户指定的起始 URL 开始爬取，按配置的最大页面数系统化探索链接
- **内容提取**：解析 HTML 以获取标题、文本内容、超链接和元数据（如 `Last-Modified` 响应头、页面大小）
- **动态刷新机制**：通过 HTTP `HEAD` 请求验证页面新鲜度，并与缓存时间戳进行条件检查
- **持久化存储**：使用 SQLite 将爬取数据存入 `webpages.db`，敏感字段（URL、标题）采用 base64 编码确保特殊字符兼容性

#### **1.2 索引构建器（`indexer.py`）**

- **倒排索引生成**：
  - **正文索引**：处理页面正文文本，经过停用词过滤和 Porter 词干提取后生成关键词及短语（2-5 词组合）
  - **标题索引**：优先处理标题内容并提升权重，采用相同分词流程
- **TF-IDF加权**：通过词频（TF）和逆文档频率（IDF）计算关键词相关性
- **数据库优化**：将索引拆分存储为 `body_inverted_index.db` 和 `title_inverted_index.db` 以加速查询

#### **1.3 检索功能（`retrieval.py`）**

- **查询解析**：支持短语查询（如"Hong Kong"）和标准关键词搜索
- **向量空间模型**：将文档和查询表示为 TF-IDF 向量，通过余弦相似度计算相关性
- **分数增强**：对标题匹配应用 2 倍权重，正文短语匹配 1.5 倍，标题短语匹配 3 倍
- **动态爬取**：按需获取未缓存页面以确保结果时效性

#### **1.4 网页界面（`webui.py`）**

- **Flask 框架界面**：提供极简风格的实时搜索界面
- **输入净化**：自动过滤非 ASCII 字符并将智能引号转换为标准形式
- **可视化增强**：高亮已访问链接，显示关键词摘要，格式化展示元数据（如页面大小、最后修改时间）

### **2. 索引数据库文件结构**

#### **2.1 `webpages.db` 结构**

- **数据表**：**`webpages`**
  - `url` (Base64)：主键，确保 URL 唯一性和安全存储
  - `title` (Base64)：处理多语言文本的页面标题
  - `date` (Base64)：符合 ISO 标准的最后修改时间戳
  - `size` (Base64)：页面字节大小
  - `body_keywords`：序列化的 `{关键词:频率}` 字典，所有字段均采用 base64 编码
  - `parent_links`/`child_links`：base64 编码的 URL 逗号分隔列表
  - `is_start` (Base64)：标识起始 URL 的标志位（`0`/`1`）

#### **2.2 倒排索引数据库**

- **正文索引（`body_inverted_index.db`）**
  - **数据表**：**`inverted_index`**
    - `keyword` (Base64)：词干化后的词项或短语（如"machine learn"对应"machine learning"）
    - `postings` (Text)：编码后的"`url`:`tf`:`tfidf`"条目，其中：
      - `url`：base64 编码的文档 URL
      - `tf`：base64 编码的词项在文档中的频率
      - `tfidf`：base64 编码的 TF-IDF 分数（保留四位小数）
- **标题索引（`title_inverted_index.db`）**
  - 结构与正文索引相同，但词项提取自页面标题

### **3. 核心算法**

#### **3.1 带条件刷新的 BFS 爬取**

- **队列管理**：使用 `deque` 实现未访问URL的先进先出处理
- **页面更新检测**：
  1. 发送 `HEAD` 请求检查 `Last-Modified` 响应头
  2. 与缓存时间戳比对，重新爬取过期页面
  3. 清理无有效父链接的孤儿页面

#### **3.2 分词与词干提取流程**

- **停用词过滤**：使用预定义列表（`stopwords.txt`）过滤常见虚词（如"the"、"and"）
- **短语提取**：从原始文本识别2-5词序列（如"search engine optimization"）
- **Porter词干提取**：将词语还原为词根形式（如"running"→"run"）以统一索引

#### **3.3 TF-IDF 计算**

- **词频（TF）**：
  `tf=(关键词在文档中的出现次数)`
  
- **逆文档频率（IDF）**：
  `idf=log(总文档数/(1+包含关键词的文档数))`
  
- **TF-IDF 权重**：
  `tfidf=tf×idf`，按文档内最大 `tf` 值归一化

#### **3.4 查询处理与排序**

- **查询向量化**：
  - 对查询词进行分词和词干提取
  - 基于两个索引的文档频率计算 TF-IDF 权重
  
- **余弦相似度**：
  `相似度=(文档向量∙查询向量)/(‖文档向量‖×‖查询向量‖)`
  
- **分数调整**：
  - 标题匹配：`分数 *= 2`
  - 正文短语匹配：`分数 *= 1.5`
  - 标题短语匹配：`分数 *= 3`

### **4. 安装与部署**

#### **4.1 先决条件**

- **Python 3.13**：需支持异步特性和库兼容性
- **依赖项**：
  - Windows：`pip install -r requirements.txt`
  - Arch Linux：`sudo pacman -S python python-requests python-lxml nltk-data python-nltk python-flask`

#### **4.2 执行步骤**

- **启动服务**：`python webui.py`
- **访问界面**：浏览器打开<http://localhost:11451>
- **注意**：首次查询可能较慢，因搜索引擎在首次查询时才开始爬取页面

#### **4.3 自定义配置**

- **调整爬取限制**：通过界面修改"Max Crawled Page"控制资源使用
- **调整结果数量**：通过界面修改"Max Results"优化显示
- **更新停用词**：编辑 `stopwords.txt` 添加领域相关噪声词

### **5. 超越要求的进阶功能**

#### **5.1 短语查询支持**

- 用户可使用引号包裹多词短语（如"deep learning"）进行精确匹配
- 引擎优先返回标题或正文包含这些短语的文档

#### **5.2 动态链接可视化**

- 搜索结果以超链接形式展示父子链接，支持用户浏览爬取图谱

#### **5.3 关键词摘要**

- 每个结果展示"关键词"字段，列出前5个词干化术语及其频率（如“algorithm 12; data 9; ...”）

#### **5.4 输入净化与兼容**

- 自动转换非 ASCII 字符和智能引号为标准形式
- 自动补全缺失的 URL 协议头（如为 `example.com` 添加 `http://`）

#### **5.5 会话级链接追踪**

- 通过 `sessionStorage` 在客户端存储已访问链接，会话期间以紫色高亮显示

### **6. 测试与验证**

提交不含非 ASCII 字符的查询（如"Café"）

- **预期**：返回有效结果
- **结果**：通过验证

### **7. 系统评估**

#### **7.1 优势**

- **模块化设计**：组件解耦，支持独立升级（如替换为分布式爬虫）
- **高效性**：SQLite 索引和内存向量运算确保中小规模语料的亚秒级响应
- **鲁棒性**：“优雅”处理畸形 HTML、编码错误和网络超时

#### **7.2 局限**

- **可扩展性**：内存向量计算在文档数超 1 万时效率显著下降
- **语言支持**：因硬编码停用词和词干规则，目前仅支持英文
- **并发能力**：单线程爬取/索引限制多核系统性能

#### **7.3 设计权衡**

- **简洁性 vs 性能**：选择 SQLite 而非 Elasticsearch/PostgreSQL 降低部署复杂度，牺牲水平扩展能力
- **准确性 vs 速度**：优先精确短语匹配而非模糊搜索，虽提升查询延迟但保证精度

#### **7.4 未来改进**

- **分布式架构**：采用 Apache Spark 或 Scrapy 实现大规模爬取/索引
- **相关性优化**：集成 PageRank 或基于 BERT 的语义相似度计算
- **多语言支持**：增加语言检测和本地化分词

#### **7.5 功能规划**

- **自动补全**：基于 Trie 树实现前缀匹配建议
- **摘要生成**：展示关键词上下文片段
- **用户反馈机制**：通过"结果是否有帮助？"投票改进排序

### **8. 贡献占比及说明**

- **于英轩** ([xuangeyouneihan](https://github.com/xuangeyouneihan)，本人)：

	75%，完成项目全部代码开发及第一阶段后所有文档撰写。

- **杜茂森** ([ThisIsNotCodingJellyfish](https://github.com/ThisIsNotCodingJellyfish))：

	24%，负责第一阶段前文档撰写，后续退出课程学习。

- **Wu Lixin（不清楚中文名）**：

	1%，申请了课程延迟退出，前期为本人和杜茂森提供部分思路。

- **Lin Xuanyu（不清楚中文名）**：

	0%，全程未与团队成员联系。

### **9. 使用的开源项目**

- [Python](https://www.python.org): PSFLv2 license

- [Requests](https://requests.readthedocs.io/en/latest): Apache-2.0 license

- [lxml](https://lxml.de): BSD-3-Clause license

- [NLTK](https://www.nltk.org): Apache-2.0 license

- [Flask](https://flask.palletsprojects.com/en/stable): Apache-2.0 license